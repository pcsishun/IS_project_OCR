{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "result_training_IS_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "76b8abbbb9b6c38b61575df51bddd0b5ac2d2320e1b6c418d8ca44efd0f1bff9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1UA1RjaovbC"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR3s2IpP6ZkB",
        "outputId": "ca10d828-0451-4c43-dc38-2f7f5728416b"
      },
      "source": [
        "pip install -U pandasql"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandasql in /usr/local/lib/python3.7/dist-packages (0.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.19.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.4.26)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->pandasql) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->pandasql) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKoGh4DXrVxq"
      },
      "source": [
        "import pandas as pd \n",
        "import pandasql as ps\n",
        "import numpy as np\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UXLaFwrH-w6",
        "outputId": "66715de2-0524-4c9d-ecad-cb94ddea4e71"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "bb_data = 'drive/My Drive/IS_project_dataset/BB_14112021.csv'\n",
        "word_data = 'drive/My Drive/IS_project_dataset/Fullword_14112021.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7mAIMIfEvUZ"
      },
      "source": [
        "func manager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km6pdauHEusB"
      },
      "source": [
        "def barcreate(data):\n",
        "  columns_n = ['label','count']\n",
        "  label_row = ['account','amount','name','notuse','refcode','timing']\n",
        "  list_save = []\n",
        "\n",
        "  for idx,i in enumerate(data):\n",
        "    row_save = label_row[idx]\n",
        "    list_save.append([row_save,i])\n",
        "\n",
        "  df_return = pd.DataFrame(data=list_save, columns=columns_n)\n",
        "  return  df_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6nd5tu0o1uT"
      },
      "source": [
        "## EDA "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2RKSruuEWMp"
      },
      "source": [
        "### count label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OMKT1wfvhVD",
        "outputId": "a5dc6a60-f676-44d2-a037-4c9d40b064e0"
      },
      "source": [
        "bb_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "Account    1108\n",
              "Amount      585\n",
              "Name        286\n",
              "NotUse     1069\n",
              "RefCode     424\n",
              "Timing     1094\n",
              "name        300\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 868
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q2egK18rfBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "d1f48601-3016-43ee-d917-f142ac84f33f"
      },
      "source": [
        "bb_df = pd.read_csv('./BB_14112021.csv')\n",
        "fullword_df = pd.read_csv('./Fullword_14112021.csv', encoding='utf8') \n",
        "\n",
        "bb_df = bb_df.drop_duplicates(subset=['word'])\n",
        "fullword_df = fullword_df.drop_duplicates(subset=['word'])\n",
        "\n",
        "bb_unique = bb_df.groupby('label').word.nunique()\n",
        "fullword_unique = fullword_df.groupby('label').word.nunique()\n",
        " \n",
        "# barplt_bb = barcreate(data=bb_unique)\n",
        "# barplt_full =barcreate(data=fullword_unique)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-877-71f5e1170940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./BB_14112021.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfullword_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Fullword_14112021.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbb_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfullword_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullword_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x81 in position 11666: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ect4yhpKEQzj",
        "outputId": "a37761a6-5652-4249-b28f-c188594b5e29"
      },
      "source": [
        "print(\"unique data full counting all word;\")\n",
        "fullword_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique data full counting all word;\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "Account    1108\n",
              "Amount      585\n",
              "Name        286\n",
              "NotUse     1068\n",
              "RefCode     424\n",
              "Timing     1094\n",
              "name        300\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 870
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syTAvZJLEaTm"
      },
      "source": [
        "print(\"unique data that only count lang;\")\n",
        "bb_unique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tECG5GdyGWgh"
      },
      "source": [
        "sns.barplot(data= barplt_bb, x='label',y='count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lFP_8YFGWu5"
      },
      "source": [
        "sns.barplot(data= barplt_full, x='label',y='count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDiZ_0ZhDHsC"
      },
      "source": [
        "### dis character count krungsri."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlQ8D98Y6Cou"
      },
      "source": [
        "displot = ps.sqldf(\"select CEng, Ctha, CNum, CSym, label from fullword_df where Bank = 'krungsri' \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAcd8CNh-wNP"
      },
      "source": [
        "ax = sns.violinplot(x=\"label\", y=\"CEng\", data=displot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4CRA0ajCySp"
      },
      "source": [
        "ax = sns.violinplot(x=\"label\", y=\"Ctha\", data=displot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHM1VTapCyjo"
      },
      "source": [
        "ax = sns.violinplot(x=\"label\", y=\"CNum\", data=displot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "draJ_ms4C2EH"
      },
      "source": [
        "ax = sns.violinplot(x=\"label\", y=\"CSym\", data=displot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkgoS7j0DX08"
      },
      "source": [
        "### dis character count Kbank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVQmEJwREmLa"
      },
      "source": [
        "Using Normalize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMF4qXLT4iD9"
      },
      "source": [
        "df = bb_df\n",
        "# df = pd.read_csv('./trainingData/TrainData_withoutWord.csv')\n",
        "df = df.drop(columns=['ID_column','Eslip_id', 'word'])\n",
        "df = pd.get_dummies(data= df, columns=['Bank'])\n",
        "range_width = df['left'] + df['width']\n",
        "range_height = df['top'] + df['height']\n",
        "df['range_width'] = range_width \n",
        "df['range_height'] = range_height\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzDU818EErOL"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "df[['left', 'top', 'width', 'height', 'CEng', 'Ctha', 'CNum', 'CSym', 'range_width', 'range_height']] = scaler.fit_transform(df[['left', 'top', 'width', 'height', 'CEng', 'Ctha', 'CNum', 'CSym', 'range_width', 'range_height']])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4SDRIdlbd_z"
      },
      "source": [
        "modelClf.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wELOeB6HHZ7G"
      },
      "source": [
        "X_trainNor, X_testNor, y_trainNor, y_testNor = train_test_split(DataNorX, DataNorY, test_size=0.2, random_state=42)\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': [1,2,3,4,5], \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "KNN_Nor_Model = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    parameters,n_jobs=-1, cv=10).fit(X_trainNor, y_trainNor)\n",
        "print(KNN_Nor_Model.best_params_)\n",
        "print(KNN_Nor_Model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QKMGCc5HrEr"
      },
      "source": [
        "y_predNor = KNN_Nor_Model.predict(X_testNor)\n",
        "print(classification_report(y_testNor,y_predNor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBDinsZXcTuT"
      },
      "source": [
        "# 1:ใช้ข้อมูลที่นับตัวอักษรทุกตัวโดยที่มีกรอบ: เทรนทุกธนาคาร\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErQksqWmHy8J"
      },
      "source": [
        "df = bb_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank','level','page_num','block_num','par_num','line_num'])\n",
        "range_width = df['left'] + df['width']\n",
        "range_height = df['top'] + df['height']\n",
        "df['range_width'] = range_width \n",
        "df['range_height'] = range_height\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXtXtO40bxYN"
      },
      "source": [
        "dataX = df.drop(columns=['label'])\n",
        "dataY = df[['label']]\n",
        "modelClf = tree.DecisionTreeClassifier().fit(dataX, dataY)\n",
        "\n",
        "array_important = []\n",
        "\n",
        "for i,j in enumerate(dataX):\n",
        "  score_f = modelClf.feature_importances_\n",
        "  print(j, '= ', score_f[i])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rx48W6z8X1P"
      },
      "source": [
        "## 1.1 KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALMXpc-G0cH"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe_qaPAGHGo7"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKIi_TDzG1EM"
      },
      "source": [
        " \n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zze05cGBcSgF"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.2, random_state=42)\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': [3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43], \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "KNN_Model = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "print('KNN',KNN_Model.best_params_)\n",
        "print('KNN',KNN_Model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w1nwmADncCp"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-OAGIw0kzlT"
      },
      "source": [
        "\n",
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CikYHQ9kpTc"
      },
      "source": [
        "y_pred = KNN_Model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyudIAKpnhCh"
      },
      "source": [
        "## 1.2 MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llydK7MmnlZl"
      },
      "source": [
        "df = bb_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank','level','page_num','block_num','par_num','line_num'])\n",
        "range_width = df['left'] + df['width']\n",
        "range_height = df['top'] + df['height']\n",
        "df['range_width'] = range_width \n",
        "df['range_height'] = range_height\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "\n",
        "dataX = df.drop(columns=['label'])\n",
        "dataY = df[['label']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNxAfWvwk-o0"
      },
      "source": [
        "parameters = {\n",
        "    'learning_rate' : ['adaptive'],\n",
        "    'hidden_layer_sizes' : [[75],[120],[149],[75,75],[120,120], [149,149]],\n",
        "    'activation' : ['relu','logistic'],\n",
        "    'solver': ['adam'],\n",
        "    'max_iter': [200,500,1000]\n",
        "}\n",
        "\n",
        "NN_model = GridSearchCV(\n",
        "    MLPClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('NN',NN_model.best_params_)\n",
        "print('NN',NN_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xzfcI8ngSD"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uk0YeWJmzkn"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP78vItfm9g8"
      },
      "source": [
        "y_pred = NN_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkt7vr8H19qF"
      },
      "source": [
        "## 1.4 Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StqvbIrxkKWE"
      },
      "source": [
        "df = bb_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank','level','page_num','block_num','par_num','line_num'])\n",
        "range_width = df['left'] + df['width']\n",
        "range_height = df['top'] + df['height']\n",
        "df['range_width'] = range_width \n",
        "df['range_height'] = range_height\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "\n",
        "dataX = df.drop(columns=['label'])\n",
        "dataY = df[['label']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaqYbWkHnEXt"
      },
      "source": [
        "parameters = {\n",
        "    'criterion' : ['gini','entropy'],\n",
        "    'splitter' : ['best','random'],\n",
        "}\n",
        "\n",
        "Tree_model = GridSearchCV(\n",
        "    DecisionTreeClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('Tree_model',Tree_model.best_params_)\n",
        "print('Tree_model',Tree_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVmKNsa7njtu"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A638pO6WnfMc"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o5RBonXnh70"
      },
      "source": [
        "y_pred = Tree_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzlnrANEfe3V"
      },
      "source": [
        "# 2:ใช้ข้อมูลที่นับตัวอักษรทุกตัวโดยที่มีกรอบ: เทรนเเค่กสิกร\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEjkp6OwfkEr"
      },
      "source": [
        "df = bb_df\n",
        " \n",
        "df = pd.get_dummies(data= df, columns=['level','page_num','block_num','par_num','line_num'])\n",
        "range_width = df['left'] + df['width']\n",
        "range_height = df['top'] + df['height']\n",
        "df['range_width'] = range_width \n",
        "df['range_height'] = range_height\n",
        "\n",
        "df_test = df[df.Bank == 'krungsri'] \n",
        "df = df[df.Bank== \"Kbank\"] \n",
        "df = df.drop(columns=['word','ID_column','Eslip_id','Bank'])\n",
        "df_test = df_test.drop(columns=['word','ID_column','Eslip_id','Bank'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3hC-r348pJY"
      },
      "source": [
        "## 2.1 KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4inUHy8JhwIs"
      },
      "source": [
        "\n",
        "X_train = df.drop(columns= ['label'])\n",
        "y_train = df[['label']]\n",
        "\n",
        "\n",
        "X_test = df_test.drop(columns= ['label'])\n",
        "y_test = df_test[['label']]\n",
        "\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': [3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43], \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "KNN_Model = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "print(KNN_Model.best_params_)\n",
        "print(KNN_Model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3WPvjDLnncL"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L_NMd3xnz5V"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tUjd5g0idik"
      },
      "source": [
        "y_pred = KNN_Model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-fqHWTsncVr"
      },
      "source": [
        "________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHQxI1sonv5P"
      },
      "source": [
        "df = bb_df\n",
        " \n",
        "df = pd.get_dummies(data= df, columns=['level','page_num','block_num','par_num','line_num'])\n",
        "range_width = df['left'] + df['width']\n",
        "range_height = df['top'] + df['height']\n",
        "df['range_width'] = range_width \n",
        "df['range_height'] = range_height\n",
        "\n",
        "df_test = df[df.Bank == 'krungsri'] \n",
        "df = df[df.Bank== \"Kbank\"] \n",
        "df = df.drop(columns=['word','ID_column','Eslip_id','Bank'])\n",
        "df_test = df_test.drop(columns=['word','ID_column','Eslip_id','Bank'])\n",
        "\n",
        "X_train = df.drop(columns= ['label'])\n",
        "y_train = df[['label']]\n",
        "\n",
        "\n",
        "X_test = df_test.drop(columns= ['label'])\n",
        "y_test = df_test[['label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0BeYfcH8tfv"
      },
      "source": [
        "## 2.2 MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsGM280DnKkc"
      },
      "source": [
        "parameters = {\n",
        "    'learning_rate' : ['adaptive',],\n",
        "    'hidden_layer_sizes' : [[75],[120],[149],[75,75],[120,120], [149,149]],\n",
        "    'activation' : ['relu','logistic'],\n",
        "    'solver': ['adam'],\n",
        "    'max_iter': [200,500,1000]\n",
        "}\n",
        "\n",
        "NN_model = GridSearchCV(MLPClassifier(),parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('NN',NN_model.best_params_)\n",
        "print('NN',NN_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufx7RuAunpDS"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxHKyLZXoRHs"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvNrL8GfnLr0"
      },
      "source": [
        "y_pred = NN_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63Clpql2FMr"
      },
      "source": [
        "## 2.4 Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSziJMyfoeBM"
      },
      "source": [
        "df = bb_df\n",
        " \n",
        "df = pd.get_dummies(data= df, columns=['level','page_num','block_num','par_num','line_num'])\n",
        "range_width = df['left'] + df['width']\n",
        "range_height = df['top'] + df['height']\n",
        "df['range_width'] = range_width \n",
        "df['range_height'] = range_height\n",
        "\n",
        "df_test = df[df.Bank == 'krungsri'] \n",
        "df = df[df.Bank== \"Kbank\"] \n",
        "df = df.drop(columns=['word','ID_column','Eslip_id','Bank'])\n",
        "df_test = df_test.drop(columns=['word','ID_column','Eslip_id','Bank'])\n",
        "\n",
        "X_train = df.drop(columns= ['label'])\n",
        "y_train = df[['label']]\n",
        "\n",
        "\n",
        "X_test = df_test.drop(columns= ['label'])\n",
        "y_test = df_test[['label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61o1ty1-og7F"
      },
      "source": [
        "parameters = {\n",
        "    'criterion' : ['gini','entropy'],\n",
        "    'splitter' : ['best','random'],\n",
        "}\n",
        "\n",
        "Tree_model = GridSearchCV(\n",
        "    DecisionTreeClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('Tree_model',Tree_model.best_params_)\n",
        "print('Tree_model',Tree_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vnbeDGYnrpt"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpRzunzEolZd"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpAIYeZZoo_k"
      },
      "source": [
        "y_pred = Tree_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUC93YbBdXr8"
      },
      "source": [
        "# 3:ใช้ข้อมูลที่นับตัวอักษรทุกตัวโดยไม่เอากรอบข้อมูลมารวม: เทรนทุกธนาคาร\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uXJNr3kdM5y"
      },
      "source": [
        "df = fullword_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank'])\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqkfJ8TKdmtD"
      },
      "source": [
        "dataX = df.drop(columns=['label'])\n",
        "dataY = df[['label']]\n",
        "modelClf = tree.DecisionTreeClassifier().fit(dataX, dataY)\n",
        "\n",
        "array_important = []\n",
        "\n",
        "# for i,j in enumerate(dataX):\n",
        "#   score_f = modelClf.feature_importances_\n",
        "#   print(j, '= ', score_f[i])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfdnEZGS8E-P"
      },
      "source": [
        "## 3.1 KNN **************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5o-RBrveJxZ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.2, random_state=42)\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': [3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43], \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "KNN_Model = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "print(KNN_Model.best_params_)\n",
        "print(KNN_Model.best_score_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMCg8d82oAjP"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYXALuk_mApI"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvbJv5SepIPh"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHFz17teTbb"
      },
      "source": [
        "y_pred = KNN_Model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce95PH664nfm"
      },
      "source": [
        "## 3.1 MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqmr_Pua4nfm"
      },
      "source": [
        "df = fullword_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank'])\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "dataX = df.drop(columns=['label'])\n",
        "dataY = df[['label']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf5HskyN4nfn"
      },
      "source": [
        "parameters = {\n",
        "    'learning_rate' : ['adaptive'],\n",
        "    'hidden_layer_sizes' : [[75],[120],[149],[75,75],[120,120], [149,149]],\n",
        "    'activation' : ['relu','logistic'],\n",
        "    'solver': ['adam'],\n",
        "    'max_iter': [200,500,1000]\n",
        "}\n",
        "\n",
        "NN_model = GridSearchCV(\n",
        "    MLPClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('NN',NN_model.best_params_)\n",
        "print('NN',NN_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnuO_U33oC9M"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwOpAcCjpWzU"
      },
      "source": [
        "\n",
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APY-LKY14nfo"
      },
      "source": [
        "y_pred = NN_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOXzzk4w2Rtr"
      },
      "source": [
        "## 3.4 Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDr4RIvSpphu"
      },
      "source": [
        "df = fullword_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank'])\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx2igqqgpp5c"
      },
      "source": [
        "parameters = {\n",
        "    'criterion' : ['gini','entropy'],\n",
        "    'splitter' : ['best','random'],\n",
        "}\n",
        "\n",
        "Tree_model = GridSearchCV(\n",
        "    DecisionTreeClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('Tree_model',Tree_model.best_params_)\n",
        "print('Tree_model',Tree_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2mOIvTooFSw"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xoHXCLepqfj"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0RgvCwCpqOw"
      },
      "source": [
        "y_pred = Tree_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mTQXag4jDz_"
      },
      "source": [
        "# 4 ใช้ข้อมูลที่นับตัวอักษรทุกตัวโดยไม่เอากรอบข้อมูลมารวม: เทรนเเค่กสิกร\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-MwK-JGeTu_"
      },
      "source": [
        "df = fullword_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank'])\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "df_test = df[df.Bank_krungsri == 1] \n",
        "df = df[df.Bank_krungsri== 0] \n",
        "df = df.drop(columns=['Bank_krungsri','Bank_Kbank'])\n",
        "df_test = df_test.drop(columns=['Bank_krungsri','Bank_Kbank'])\n",
        "\n",
        "# print(df)\n",
        "# print('\\n')\n",
        "# print(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRxyMDHd8xiX"
      },
      "source": [
        "## 4.1 KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEU9-IphjZ2k"
      },
      "source": [
        "\n",
        "X_train = df.drop(columns= ['label'])\n",
        "y_train = df[['label']]\n",
        "\n",
        "\n",
        "X_test = df_test.drop(columns= ['label'])\n",
        "y_test = df_test[['label']]\n",
        "\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': [3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43], \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "KNN_Model = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "print(KNN_Model.best_params_)\n",
        "print(KNN_Model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKST1NLooIBo"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtkIzdi_XC-8"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5A30YZvp1vN"
      },
      "source": [
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYwR-dVUjjQz"
      },
      "source": [
        "y_pred = KNN_Model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87yT-I8J4nfp"
      },
      "source": [
        "## 4.2 MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_ypf8dM4nfp"
      },
      "source": [
        "df = fullword_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank'])\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "df_test = df[df.Bank_krungsri == 1] \n",
        "df = df[df.Bank_krungsri== 0] \n",
        "df = df.drop(columns=['Bank_krungsri','Bank_Kbank'])\n",
        "df_test = df_test.drop(columns=['Bank_krungsri','Bank_Kbank'])\n",
        "\n",
        "\n",
        "X_train = df.drop(columns= ['label'])\n",
        "y_train = df[['label']]\n",
        "\n",
        "\n",
        "X_test = df_test.drop(columns= ['label'])\n",
        "y_test = df_test[['label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9MOP8qV4nfq"
      },
      "source": [
        "parameters = {\n",
        "    'learning_rate' : ['adaptive',],\n",
        "    'hidden_layer_sizes' : [[75],[120],[149],[75,75],[120,120], [149,149]],\n",
        "    'activation' : ['relu','logistic'],\n",
        "    'solver': ['adam'],\n",
        "    'max_iter': [200,500,1000]\n",
        "}\n",
        "\n",
        "NN_model = GridSearchCV(\n",
        "    MLPClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('NN',NN_model.best_params_)\n",
        "print('NN',NN_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptzE6hiQoKoH"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93y0pNcUqBjf"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uo5wy7T4nfq"
      },
      "source": [
        "y_pred = NN_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9wiDwNI2T9b"
      },
      "source": [
        "## 4.4 Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S99T_uM0p9J4"
      },
      "source": [
        "df = fullword_df\n",
        "df = pd.get_dummies(data= df, columns=['Bank'])\n",
        "df = df.drop(columns=['word','ID_column','Eslip_id'])\n",
        "df_test = df[df.Bank_krungsri == 1] \n",
        "df = df[df.Bank_krungsri== 0] \n",
        "df = df.drop(columns=['Bank_krungsri','Bank_Kbank'])\n",
        "df_test = df_test.drop(columns=['Bank_krungsri','Bank_Kbank'])\n",
        "\n",
        "\n",
        "\n",
        "X_train = df.drop(columns= ['label'])\n",
        "y_train = df[['label']]\n",
        "\n",
        "\n",
        "X_test = df_test.drop(columns= ['label'])\n",
        "y_test = df_test[['label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjQgq_eRqJQz"
      },
      "source": [
        "parameters = {\n",
        "    'criterion' : ['gini','entropy'],\n",
        "    'splitter' : ['best','random'],\n",
        "}\n",
        "\n",
        "Tree_model = GridSearchCV(\n",
        "    DecisionTreeClassifier(),\n",
        "    parameters,n_jobs=-1, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print('Tree_model',Tree_model.best_params_)\n",
        "print('Tree_model',Tree_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpOyIsqGoNEs"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_train.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_train.groupby(['label']).size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8WdkW_sqLB0"
      },
      "source": [
        "print('Count unique y_train')\n",
        "label_y = y_test.label.unique()\n",
        "print(label_y)\n",
        "print('\\n')\n",
        "print(y_test.groupby(['label']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QgCbutMqMna"
      },
      "source": [
        "y_pred = Tree_model.predict(X_test)\n",
        "confusionData = confusion_matrix(y_test, y_pred, labels=label_y)\n",
        "confusionFrame = pd.DataFrame(data=confusionData, columns=label_y)\n",
        "print(confusionFrame)\n",
        "# print(confusion_matrix(y_test, y_pred, labels=label_y))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW8j3QMFoIof"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}